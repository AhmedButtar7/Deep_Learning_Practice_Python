# Deep Learning Practice - Improving Deep Neural Networks (Module 2)

This repository contains my implementations and notes for **Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization**, which is Module 2 of my deep learning journey. This module focuses on advanced techniques to optimize and improve the performance of deep neural networks.

## ğŸ“‚ Repository Structure

```
Improving Deep Neural Networks Hyperparameter Tuning, Regularization and Optimization (Module 2)/
â”œâ”€â”€ Week 1 - Practical Aspects of Deep Learning/
â”‚   â”œâ”€â”€ Initialization/
â”‚   â”‚   â”œâ”€â”€ Initialization.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Regularization/
â”‚   â”‚   â”œâ”€â”€ Regularization.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Gradient Checking/
â”‚   â”‚   â”œâ”€â”€ Gradient_Checking.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Week 2 - Optimization Algorithms/
â”‚   â”œâ”€â”€ Optimization Methods/
â”‚   â”‚   â”œâ”€â”€ Optimization_methods.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Week 3 - Hyperparameter Tuning, Batch Normalization and Programming Frameworks/
â”‚   â”œâ”€â”€ TensorFlow Tutorial/
â”‚   â”‚   â”œâ”€â”€ TensorFlow_Tutorial.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Hyperparameter Tuning/
â”‚   â”‚   â”œâ”€â”€ Hyperparameter_tuning.ipynb
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

## ğŸ“Œ Weekly Breakdown

### **Week 1: Practical Aspects of Deep Learning**
- **Initialization**: Comparing different weight initialization techniques and their impact on model convergence.
- **Regularization**: Implementing L2 regularization and dropout to prevent overfitting.
- **Gradient Checking**: Verifying the correctness of backpropagation implementation using numerical gradient methods.

#### Key Concepts:
- Importance of proper weight initialization (Zero, Random, He, Xavier)
- Regularization techniques (L2, Dropout)
- Gradient checking implementation and best practices
- Overfitting detection and prevention strategies

---

### **Week 2: Optimization Algorithms**
- **Optimization Methods**: Implementing various optimization algorithms beyond basic gradient descent.

#### Key Concepts:
- Mini-batch gradient descent
- Exponentially weighted averages
- Momentum optimization
- RMSProp
- Adam optimization algorithm
- Learning rate decay techniques

---

### **Week 3: Hyperparameter Tuning, Batch Normalization and Programming Frameworks**
- **TensorFlow Tutorial**: Introduction to TensorFlow for deep learning implementations.
- **Hyperparameter Tuning**: Systematic approaches for tuning hyperparameters.
- **Batch Normalization**: Implementing batch normalization to accelerate deep network training.

#### Key Concepts:
- TensorFlow basics and computational graphs
- Hyperparameter tuning strategies (random vs. grid search)
- Batch normalization implementation and benefits
- Multi-class classification with softmax regression
- Introduction to deep learning frameworks

## ğŸ› ï¸ Dependencies
- Python 3.7+
- NumPy
- TensorFlow 2.x
- Matplotlib (for visualization)
- Jupyter Notebook
- scikit-learn (for some datasets and utilities)

## ğŸš€ How to Use This Repository
1. Clone the repo:
   ```bash
   git clone https://github.com/AhmedButtar7/Deep_Learning_Practice_Python.git
   ```
2. Navigate to Module 2:
   ```bash
   cd "Improving Deep Neural Networks Hyperparameter Tuning, Regularization and Optimization (Module 2)"
   ```
3. Open and run the Jupyter Notebooks in weekly order:
   ```bash
   jupyter notebook
   ```

## ğŸ“ Key Implementations

### Regularization Techniques
- L2 regularization implementation
- Dropout forward and backward propagation
- Early stopping mechanisms

### Optimization Algorithms
- Mini-batch gradient descent
- Momentum optimization
- RMSProp optimizer
- Adam optimization algorithm

### Advanced Concepts
- Batch normalization for deep networks
- Hyperparameter tuning with systematic approaches
- TensorFlow implementation of neural networks

## ğŸ”— References
- [Deep Learning Specialization - Coursera](https://www.coursera.org/specializations/deep-learning)
- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [Original Course Materials](https://www.coursera.org/learn/deep-neural-network)

---

**Happy Learning!** ğŸš€  
**Ahmed Buttar**  
ğŸ“§ [Email](mailto:muhanmadahmed02@gmail.com) | ğŸ”— [GitHub](https://github.com/AhmedButtar7) | ğŸ’¼ [LinkedIn]([https://linkedin.com/in/ahmedbuttar](https://www.linkedin.com/in/muhammad-ahmed-a29142349?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app))
